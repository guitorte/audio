{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸµ Complete Audio Restoration Pipeline with Demucs\n",
    "\n",
    "## âœ¨ Features:\n",
    "\n",
    "**Full Professional Audio Processing:**\n",
    "- âœ… **Spectral Analysis** - Analyze audio quality and issues\n",
    "- âœ… **Noise Reduction** - Remove background noise intelligently\n",
    "- âœ… **Frequency Restoration** - Restore missing high frequencies\n",
    "- âœ… **Stem Separation with Demucs** - Separate vocals, drums, bass, other (state-of-the-art AI)\n",
    "- âœ… **Mastering** - Professional EQ, compression, limiting\n",
    "- âœ… **LUFS Normalization** - Streaming-ready loudness\n",
    "\n",
    "## ğŸ”§ Technical Details:\n",
    "\n",
    "**Demucs Integration:**\n",
    "- Uses `htdemucs` model (4 stems: vocals, drums, bass, other)\n",
    "- Automatic FFmpeg installation (required dependency)\n",
    "- Automatic TorchCodec installation (required for file saving)\n",
    "- GPU acceleration if available\n",
    "- Fallback to basic HPSS method if Demucs fails\n",
    "\n",
    "## â±ï¸ Processing Time:\n",
    "- **Without Demucs:** 1-2 minutes per track\n",
    "- **With Demucs (CPU):** 10-20 minutes per track\n",
    "- **With Demucs (GPU):** 3-5 minutes per track\n",
    "\n",
    "## ğŸš€ Quick Start:\n",
    "\n",
    "1. Run all cells in order\n",
    "2. Upload your audio file\n",
    "3. Choose a processing configuration\n",
    "4. Get professional results!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Step 1: Install Dependencies\n",
    "\n",
    "**This will install:**\n",
    "- Audio processing libraries (librosa, soundfile, scipy)\n",
    "- Demucs for stem separation\n",
    "- TorchCodec for Demucs file operations\n",
    "- FFmpeg (system package)\n",
    "\n",
    "**Time:** ~2-3 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%capture\n# Install Python packages\n!pip install -q librosa soundfile scipy numpy matplotlib ipywidgets\n!pip install -q demucs torchcodec\n\nprint(\"âœ“ Python packages installed!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install FFmpeg (required for Demucs)\n",
    "print(\"ğŸ” Checking FFmpeg...\")\n",
    "import subprocess\n",
    "\n",
    "ffmpeg_check = subprocess.run(['ffmpeg', '-version'], capture_output=True)\n",
    "\n",
    "if ffmpeg_check.returncode != 0:\n",
    "    print(\"âš ï¸  FFmpeg not found. Installing...\")\n",
    "    !apt-get update -qq\n",
    "    !apt-get install -y -qq ffmpeg\n",
    "    print(\"âœ“ FFmpeg installed!\")\n",
    "else:\n",
    "    print(\"âœ“ FFmpeg already installed!\")\n",
    "\n",
    "# Verify installation\n",
    "!ffmpeg -version | head -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Step 2: Download Audio Restoration Pipeline\n",
    "\n",
    "**Downloads the complete pipeline from GitHub**\n",
    "\n",
    "**Time:** ~5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Remove old version if exists\n",
    "!rm -rf /content/audio-pipeline\n",
    "\n",
    "# Clone the repository\n",
    "print(\"ğŸ“¥ Downloading audio restoration pipeline...\")\n",
    "!git clone -q -b claude/audio-restoration-pipeline-gAFxk \\\n",
    "  https://github.com/guitorte/musicas.git \\\n",
    "  /content/audio-pipeline\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.insert(0, '/content/audio-pipeline/audio-restoration-pipeline')\n",
    "\n",
    "print(\"âœ“ Pipeline downloaded!\")\n",
    "print(\"âœ“ Ready to process audio!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ“‚ Step 3: Mount Google Drive & Select File\n\n**Mounts your Google Drive and lets you choose which file to restore from `00-restore` folder**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import drive\nimport os\nimport glob\nfrom pathlib import Path\nimport ipywidgets as widgets\nfrom IPython.display import display\n\n# Mount Google Drive\nprint(\"ğŸ“‚ Mounting Google Drive...\")\ndrive.mount('/content/drive')\n\n# Define input/output directories\nAUDIO_INPUT_DIR = '/content/drive/MyDrive/00-restore'\nAUDIO_OUTPUT_DIR = '/content/drive/MyDrive/00-restore/restored_output'\n\nprint(f\"âœ“ Drive mounted!\")\nprint(f\"ğŸ“ Input folder: {AUDIO_INPUT_DIR}\")\nprint(f\"ğŸ“ Output folder: {AUDIO_OUTPUT_DIR}\")\n\n# Create output directory\nos.makedirs(AUDIO_OUTPUT_DIR, exist_ok=True)\n\nprint(\"\\n\" + \"=\"*70)\n\n# Find all audio files\naudio_files = []\nfor ext in ['*.mp3', '*.wav', '*.MP3', '*.WAV', '*.m4a', '*.M4A', '*.flac', '*.FLAC']:\n    audio_files.extend(glob.glob(os.path.join(AUDIO_INPUT_DIR, ext)))\n\naudio_files = sorted(set(audio_files))\n\nprint(f\"âœ“ Found {len(audio_files)} audio file(s)\\n\")\n\nif not audio_files:\n    print(f\"âš ï¸  No audio files found in {AUDIO_INPUT_DIR}\")\n    print(\"   Please add audio files to your '00-restore' folder in Google Drive\")\nelse:\n    # List all files\n    for i, file in enumerate(audio_files, 1):\n        size_mb = os.path.getsize(file) / (1024 * 1024)\n        name = Path(file).name\n        print(f\"{i:2d}. {name[:55]:55s} ({size_mb:6.2f} MB)\")\n    \n    print(\"\\n\" + \"=\"*70)\n    \n    # Create dropdown options with file info\n    file_options = []\n    for i, file in enumerate(audio_files):\n        size_mb = os.path.getsize(file) / (1024 * 1024)\n        name = Path(file).name\n        file_options.append((f\"{i+1}. {name} ({size_mb:.2f} MB)\", i))\n    \n    # Create dropdown widget\n    file_selector = widgets.Dropdown(\n        options=file_options,\n        value=0,\n        description='Select file:',\n        style={'description_width': 'initial'},\n        layout=widgets.Layout(width='90%')\n    )\n    \n    # Info label for selected file\n    info_label = widgets.HTML(value=\"\")\n    \n    # Function to update info when selection changes\n    def on_file_change(change):\n        idx = change['new']\n        selected_file = audio_files[idx]\n        size_mb = os.path.getsize(selected_file) / (1024 * 1024)\n        duration_info = \"\"\n        try:\n            import librosa\n            total_duration = librosa.get_duration(path=selected_file)\n            duration_info = f\"<br><b>Duration:</b> {total_duration:.1f}s ({total_duration/60:.1f} min)\"\n        except:\n            pass\n        info_label.value = f\"<b>Selected:</b> {Path(selected_file).name}<br><b>Size:</b> {size_mb:.2f} MB{duration_info}\"\n    \n    # Connect event\n    file_selector.observe(on_file_change, names='value')\n    \n    # Trigger initial display\n    on_file_change({'new': 0})\n    \n    print(\"\\nğŸµ SELECT THE FILE TO RESTORE:\")\n    display(file_selector)\n    display(info_label)\n    \n    # Set global variables for use in other cells\n    audio_file = Path(audio_files[0]).name\n    audio_path = audio_files[0]\n    \n    def get_selected_file():\n        \"\"\"Returns the currently selected file path\"\"\"\n        return audio_files[file_selector.value]\n    \n    def get_selected_filename():\n        \"\"\"Returns just the filename of the selected file\"\"\"\n        return Path(audio_files[file_selector.value]).name\n    \n    print(\"\\nğŸ’¡ Use the dropdown above to select your file, then run the next cells\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 4: Analyze Audio\n",
    "\n",
    "**Analyzes your audio to determine optimal processing settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import librosa\nimport numpy as np\nfrom pathlib import Path\n\n# Use selected file from dropdown\nif 'file_selector' in dir():\n    audio_path = get_selected_file()\nelse:\n    print(\"âš ï¸  Run Step 3 first to select a file!\")\n    audio_path = None\n\nif audio_path:\n    print(\"=\"*70)\n    print(f\"ğŸµ ANALYZING: {Path(audio_path).name}\")\n    print(\"=\"*70)\n\n    # Load audio\n    y, sr = librosa.load(audio_path, sr=44100)\n    duration = len(y) / sr\n\n    # Basic metrics\n    print(f\"\\nğŸ“Š Basic Info:\")\n    print(f\"  Duration: {duration:.1f}s ({duration/60:.1f} minutes)\")\n    print(f\"  Sample Rate: {sr} Hz\")\n    print(f\"  Samples: {len(y):,}\")\n\n    # Loudness analysis\n    rms = np.sqrt(np.mean(y**2))\n    lufs_approx = 20 * np.log10(rms + 1e-10) + 0.691\n    peak = np.max(np.abs(y))\n    dynamic_range = 20 * np.log10(peak / (rms + 1e-10))\n\n    print(f\"\\nğŸ”Š Loudness:\")\n    print(f\"  LUFS: {lufs_approx:.1f} dB\")\n    print(f\"  Peak: {peak:.3f} ({20*np.log10(peak):.1f} dBFS)\")\n    print(f\"  Dynamic Range: {dynamic_range:.1f} dB\")\n\n    # Frequency analysis\n    S = np.abs(librosa.stft(y))\n    freqs = librosa.fft_frequencies(sr=sr)\n\n    bass_mask = (freqs >= 20) & (freqs < 250)\n    mid_mask = (freqs >= 250) & (freqs < 2000)\n    high_mask = (freqs >= 2000) & (freqs < 8000)\n    air_mask = (freqs >= 8000)\n\n    bass_energy = np.mean(S[bass_mask, :])\n    mid_energy = np.mean(S[mid_mask, :])\n    high_energy = np.mean(S[high_mask, :])\n    air_energy = np.mean(S[air_mask, :])\n\n    total_energy = bass_energy + mid_energy + high_energy + air_energy\n\n    print(f\"\\nğŸ¼ Frequency Balance:\")\n    print(f\"  Bass (20-250 Hz):   {100*bass_energy/total_energy:.1f}%\")\n    print(f\"  Mids (250-2k Hz):   {100*mid_energy/total_energy:.1f}%\")\n    print(f\"  Highs (2-8 kHz):    {100*high_energy/total_energy:.1f}%\")\n    print(f\"  Air (8+ kHz):       {100*air_energy/total_energy:.1f}%\")\n\n    # Noise estimation\n    noise_floor = np.percentile(np.abs(y), 5)\n    signal_peak = np.percentile(np.abs(y), 95)\n    snr_estimate = 20 * np.log10(signal_peak / (noise_floor + 1e-10))\n\n    print(f\"\\nğŸ“‰ Noise Level:\")\n    print(f\"  SNR: {snr_estimate:.1f} dB\")\n    if snr_estimate < 20:\n        print(f\"  âš ï¸  High noise - strong reduction recommended\")\n    elif snr_estimate < 30:\n        print(f\"  ğŸ’¡ Moderate noise - medium reduction recommended\")\n    else:\n        print(f\"  âœ“ Clean signal - light reduction only\")\n\n    # Quality checks\n    print(f\"\\nâœ“ Quality Checks:\")\n    if peak > 0.99:\n        print(f\"  âš ï¸  Clipping detected!\")\n    else:\n        print(f\"  âœ“ No clipping\")\n\n    if lufs_approx < -20:\n        print(f\"  âš ï¸  Very quiet (needs gain)\")\n    elif lufs_approx > -10:\n        print(f\"  âš ï¸  Very loud (may be over-compressed)\")\n    else:\n        print(f\"  âœ“ Good loudness\")\n\n    print(\"\\n\" + \"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Step 5: Configure Processing\n",
    "\n",
    "**Choose your processing preset:**\n",
    "\n",
    "### Available Presets:\n",
    "\n",
    "1. **`CONFIG_FULL_WITH_DEMUCS`** - Complete restoration with AI stem separation\n",
    "   - Stem separation with Demucs (vocals, drums, bass, other)\n",
    "   - Noise reduction, frequency restoration\n",
    "   - Professional mastering\n",
    "   - **â±ï¸ Time:** 10-20 min (CPU) or 3-5 min (GPU)\n",
    "   - **Best for:** Tracks that need stem-level processing\n",
    "\n",
    "2. **`CONFIG_STANDARD`** - Professional restoration without Demucs\n",
    "   - Noise reduction, frequency restoration\n",
    "   - Professional EQ and mastering\n",
    "   - **â±ï¸ Time:** 1-2 minutes\n",
    "   - **Best for:** Most tracks (recommended)\n",
    "\n",
    "3. **`CONFIG_CONSERVATIVE`** - Gentle improvements only\n",
    "   - Light processing, preserves character\n",
    "   - **â±ï¸ Time:** 1 minute\n",
    "   - **Best for:** Already good quality tracks\n",
    "\n",
    "4. **`CONFIG_MASTERING_ONLY`** - Mastering only (no restoration)\n",
    "   - EQ, compression, limiting, LUFS normalization\n",
    "   - **â±ï¸ Time:** 30 seconds\n",
    "   - **Best for:** Clean tracks that just need final polish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# CONFIGURATION PRESETS\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n# 1. FULL PROCESSING WITH DEMUCS (Slowest, highest quality)\nCONFIG_FULL_WITH_DEMUCS = {\n    'remove_clicks': True,\n    'reduce_noise': True,\n    'noise_reduction_strength': 0.5,\n    'restore_frequencies': True,\n    'freq_restoration_method': 'harmonic_synthesis',\n    'psychoacoustic_enhancement': True,\n    'separate_stems': True,  # âš ï¸ This enables Demucs (slow!)\n    'stem_model': 'demucs',\n    'target_lufs': -14.0,\n    'master_eq': {\n        'bass': 0.5,\n        'mid': 0.0,\n        'presence': 1.0,\n        'treble': 0.8\n    },\n    'add_presence': True\n}\n\n# 2. STANDARD PROFESSIONAL (Fast, no Demucs)\nCONFIG_STANDARD = {\n    'remove_clicks': True,\n    'reduce_noise': True,\n    'noise_reduction_strength': 0.4,\n    'restore_frequencies': True,\n    'freq_restoration_method': 'harmonic_synthesis',\n    'psychoacoustic_enhancement': True,\n    'separate_stems': False,  # No Demucs - fast processing\n    'target_lufs': -14.0,\n    'master_eq': {\n        'bass': 0.5,\n        'mid': 0.0,\n        'presence': 1.0,\n        'treble': 0.8\n    },\n    'add_presence': True\n}\n\n# 3. CONSERVATIVE (Very fast, gentle)\nCONFIG_CONSERVATIVE = {\n    'remove_clicks': True,\n    'reduce_noise': True,\n    'noise_reduction_strength': 0.3,\n    'restore_frequencies': False,\n    'separate_stems': False,\n    'target_lufs': -14.0,\n    'master_eq': {\n        'bass': 0.0,\n        'mid': 0.0,\n        'presence': 0.5,\n        'treble': 0.3\n    },\n    'add_presence': False\n}\n\n# 4. MASTERING ONLY (Fastest)\nCONFIG_MASTERING_ONLY = {\n    'remove_clicks': False,\n    'reduce_noise': False,\n    'restore_frequencies': False,\n    'separate_stems': False,\n    'target_lufs': -14.0,\n    'master_eq': {\n        'bass': 0.5,\n        'mid': 0.0,\n        'presence': 1.0,\n        'treble': 0.8\n    },\n    'add_presence': True\n}\n\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n# SELECT YOUR CONFIG HERE:\n# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nCONFIG = CONFIG_FULL_WITH_DEMUCS  # â­ Change this to select a preset\n\n# Detect which config was selected\nconfig_name = \"CUSTOM\"\nif CONFIG == CONFIG_FULL_WITH_DEMUCS:\n    config_name = \"CONFIG_FULL_WITH_DEMUCS\"\nelif CONFIG == CONFIG_STANDARD:\n    config_name = \"CONFIG_STANDARD\"\nelif CONFIG == CONFIG_CONSERVATIVE:\n    config_name = \"CONFIG_CONSERVATIVE\"\nelif CONFIG == CONFIG_MASTERING_ONLY:\n    config_name = \"CONFIG_MASTERING_ONLY\"\n\n# Display selected config\nprint(\"=\"*70)\nprint(\"âœ“ CONFIGURATION LOADED\")\nprint(\"=\"*70)\nprint(f\"\\nSelected: {config_name}\")\nprint(f\"\\nSettings:\")\nprint(f\"  â€¢ Noise Reduction: {CONFIG['noise_reduction_strength']}\")\nprint(f\"  â€¢ Frequency Restoration: {CONFIG['restore_frequencies']}\")\nprint(f\"  â€¢ Stem Separation (Demucs): {CONFIG['separate_stems']}\")\nprint(f\"  â€¢ Target LUFS: {CONFIG['target_lufs']} dB\")\n\nif CONFIG['separate_stems']:\n    print(f\"\\nâš ï¸  Demucs enabled - this will take 10-20 minutes!\")\n    print(f\"   Set CONFIG = CONFIG_STANDARD for faster processing without Demucs\")\nelse:\n    print(f\"\\nâœ“ Fast processing - no Demucs (1-2 minutes)\")\n    print(f\"   Set CONFIG = CONFIG_FULL_WITH_DEMUCS to enable stem separation\")\n\nprint(\"\\n\" + \"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸµ Step 6: PROCESS!\n",
    "\n",
    "**This will process your audio with the selected configuration**\n",
    "\n",
    "### What happens:\n",
    "1. **Stage 1:** Spectral analysis\n",
    "2. **Stage 2:** Noise reduction and cleanup\n",
    "3. **Stage 3:** Frequency restoration\n",
    "4. **Stage 4:** Stem separation (if enabled)\n",
    "5. **Stage 5:** Mastering (EQ, compression, limiting)\n",
    "6. **Stage 6:** LUFS normalization\n",
    "\n",
    "### Time estimates:\n",
    "- **With Demucs:** 10-20 minutes (CPU) or 3-5 minutes (GPU)\n",
    "- **Without Demucs:** 1-2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from modules import AudioRestorationPipeline\nfrom pathlib import Path\nimport json\n\n# Use selected file from dropdown\nif 'file_selector' in dir():\n    audio_path = get_selected_file()\nelse:\n    print(\"âš ï¸  Run Step 3 first to select a file!\")\n    audio_path = None\n\nif audio_path:\n    print(\"=\"*70)\n    print(\"ğŸµ STARTING AUDIO PROCESSING\")\n    print(\"=\"*70)\n\n    # Initialize pipeline - output to Google Drive\n    pipeline = AudioRestorationPipeline(\n        sr=44100,\n        output_base_dir=AUDIO_OUTPUT_DIR,\n        log_dir=os.path.join(AUDIO_OUTPUT_DIR, 'logs')\n    )\n\n    # Process\n    filename = Path(audio_path).stem\n    print(f\"\\nProcessing: {Path(audio_path).name}\")\n    print(f\"Output folder: {AUDIO_OUTPUT_DIR}\")\n    print(\"\\n\" + \"=\"*70 + \"\\n\")\n\n    result = pipeline.process_audio(\n        audio_path,\n        output_name=filename,\n        config=CONFIG\n    )\n\n    print(\"\\n\" + \"=\"*70)\n    print(\"âœ“âœ“âœ“ PROCESSING COMPLETE! âœ“âœ“âœ“\")\n    print(\"=\"*70)\n\n    # Save results\n    result_path = os.path.join(AUDIO_OUTPUT_DIR, 'processing_result.json')\n    with open(result_path, 'w') as f:\n        json.dump(result, f, indent=2)\n\n    final_wav = result['stages']['mastering']['output']\n    print(f\"\\nğŸ“ Final output: {final_wav}\")\n    print(f\"ğŸ“Š Results: {result_path}\")\n\n    # Copy to easy location in Drive\n    final_name = f\"{filename}_MASTERED.wav\"\n    final_output_path = os.path.join(AUDIO_OUTPUT_DIR, final_name)\n    !cp \"{final_wav}\" \"{final_output_path}\"\n\n    print(f\"\\nâœ“ Saved to: {final_output_path}\")\n    print(f\"\\nğŸ’¡ File is now in your Google Drive '00-restore/restored_output' folder!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ Step 7: Listen to Results\n",
    "\n",
    "**Compare before and after**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from IPython.display import Audio, display\nimport glob\n\nprint(\"=\"*70)\nprint(\"ğŸ§ BEFORE vs AFTER COMPARISON\")\nprint(\"=\"*70)\n\n# Use the selected file\nif 'file_selector' in dir():\n    audio_path = get_selected_file()\n    \n    print(\"\\nğŸ”´ BEFORE (Original):\")\n    display(Audio(audio_path))\n\n    print(\"\\nğŸŸ¢ AFTER (Mastered):\")\n    # Find mastered file in Drive output folder\n    mastered_files = glob.glob(os.path.join(AUDIO_OUTPUT_DIR, '*_MASTERED.wav'))\n    if mastered_files:\n        # Use the most recent one\n        latest_mastered = max(mastered_files, key=os.path.getctime)\n        display(Audio(latest_mastered))\n        print(f\"   File: {Path(latest_mastered).name}\")\n    else:\n        print(\"âš ï¸  Mastered file not found. Run Step 6 first.\")\n\n    print(\"\\nğŸ’¡ Listen with headphones for best results!\")\nelse:\n    print(\"âš ï¸  Run Step 3 first to select a file!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 8: Analysis Report\n",
    "\n",
    "**See detailed before/after metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import librosa\nimport numpy as np\n\nprint(\"=\"*70)\nprint(\"ğŸ“Š BEFORE vs AFTER ANALYSIS\")\nprint(\"=\"*70)\n\nif 'file_selector' in dir():\n    audio_path = get_selected_file()\n    \n    # Load original\n    y_orig, sr = librosa.load(audio_path, sr=44100)\n    rms_orig = np.sqrt(np.mean(y_orig**2))\n    lufs_orig = 20 * np.log10(rms_orig + 1e-10) + 0.691\n    peak_orig = np.max(np.abs(y_orig))\n\n    print(\"\\nğŸ”´ ORIGINAL:\")\n    print(f\"  LUFS: {lufs_orig:.1f} dB\")\n    print(f\"  Peak: {peak_orig:.3f}\")\n\n    # Load mastered\n    mastered_files = glob.glob(os.path.join(AUDIO_OUTPUT_DIR, '*_MASTERED.wav'))\n    if mastered_files:\n        latest_mastered = max(mastered_files, key=os.path.getctime)\n        y_mast, sr = librosa.load(latest_mastered, sr=44100)\n        rms_mast = np.sqrt(np.mean(y_mast**2))\n        lufs_mast = 20 * np.log10(rms_mast + 1e-10) + 0.691\n        peak_mast = np.max(np.abs(y_mast))\n\n        print(\"\\nğŸŸ¢ MASTERED:\")\n        print(f\"  LUFS: {lufs_mast:.1f} dB\")\n        print(f\"  Peak: {peak_mast:.3f}\")\n\n        print(\"\\nğŸ“Š IMPROVEMENTS:\")\n        print(f\"  LUFS: {lufs_orig:.1f} â†’ {lufs_mast:.1f} ({lufs_mast - lufs_orig:+.1f} dB)\")\n        print(f\"  Peak: {peak_orig:.3f} â†’ {peak_mast:.3f}\")\n\n        print(\"\\nâœ“ QUALITY CHECKS:\")\n        if abs(lufs_mast + 14) < 1:\n            print(\"  âœ“ Perfect for Spotify/YouTube/Apple Music\")\n        if peak_mast < 0.99:\n            print(\"  âœ“ No clipping detected\")\n        if abs(lufs_mast - lufs_orig) > 0.5:\n            print(\"  âœ“ Loudness normalized successfully\")\n    else:\n        print(\"\\nâš ï¸  Mastered file not found. Run Step 6 first.\")\nelse:\n    print(\"âš ï¸  Run Step 3 first to select a file!\")\n\nprint(\"\\n\" + \"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Step 9: Download Results\n",
    "\n",
    "**Download your mastered audio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import files\nimport glob\nimport os\n\nprint(\"ğŸ“¥ DOWNLOAD OPTIONS\")\nprint(\"=\"*70)\n\nprint(\"\\nâœ“ Files are already saved to your Google Drive!\")\nprint(f\"   Location: {AUDIO_OUTPUT_DIR}\")\n\n# List files in output folder\nmastered_files = glob.glob(os.path.join(AUDIO_OUTPUT_DIR, '*_MASTERED.wav'))\n\nif mastered_files:\n    print(f\"\\nğŸ“ Mastered Files ({len(mastered_files)}):\")\n    for wav in mastered_files:\n        size = os.path.getsize(wav) / (1024*1024)\n        print(f\"   â€¢ {Path(wav).name} ({size:.1f} MB)\")\n    \n    print(\"\\nğŸ’¡ To download to your computer, uncomment and run:\")\n    print(\"   # files.download(mastered_files[0])\")\n    \n    # Uncomment below to download\n    # for wav in mastered_files:\n    #     files.download(wav)\n\n# Option 2: Download individual stems (if Demucs was used)\nif 'result' in dir() and CONFIG.get('separate_stems', False):\n    stem_files = glob.glob(f\"{result['output_dir']}/**/*.wav\", recursive=True)\n    stem_files = [f for f in stem_files if any(stem in f for stem in ['vocals', 'drums', 'bass', 'other'])]\n    \n    if stem_files:\n        print(f\"\\nğŸ“ Individual Stems ({len(stem_files)}):\")\n        for stem in stem_files:\n            print(f\"   â€¢ {Path(stem).name}\")\n        \n        print(\"\\nğŸ’¡ Uncomment below to download stems:\")\n        # for stem in stem_files:\n        #     files.download(stem)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"âœ“ All files saved to Google Drive!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Step 10: View Stems (If Demucs Was Used)\n",
    "\n",
    "**Listen to individual separated stems**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if CONFIG.get('separate_stems', False) and 'result' in dir():\n    print(\"=\"*70)\n    print(\"ğŸ¼ INDIVIDUAL STEMS (Demucs Separation)\")\n    print(\"=\"*70)\n    \n    # Find stems\n    stem_files = glob.glob(f\"{result['output_dir']}/**/*.wav\", recursive=True)\n    \n    stems = {}\n    for f in stem_files:\n        name = Path(f).stem.lower()\n        if 'vocals' in name:\n            stems['vocals'] = f\n        elif 'drums' in name:\n            stems['drums'] = f\n        elif 'bass' in name:\n            stems['bass'] = f\n        elif 'other' in name:\n            stems['other'] = f\n    \n    # Display each stem\n    if 'vocals' in stems:\n        print(\"\\nğŸ¤ VOCALS:\")\n        display(Audio(stems['vocals']))\n    \n    if 'drums' in stems:\n        print(\"\\nğŸ¥ DRUMS:\")\n        display(Audio(stems['drums']))\n    \n    if 'bass' in stems:\n        print(\"\\nğŸ¸ BASS:\")\n        display(Audio(stems['bass']))\n    \n    if 'other' in stems:\n        print(\"\\nğŸ¹ OTHER (Instruments):\")\n        display(Audio(stems['other']))\n    \n    print(\"\\n\" + \"=\"*70)\nelse:\n    print(\"\\nâš ï¸  Stem separation was not enabled or processing hasn't run yet.\")\n    print(\"   Set CONFIG = CONFIG_FULL_WITH_DEMUCS to enable Demucs\")\n    print(\"   Then run Step 6 to process the audio\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¡ Tips & Troubleshooting\n",
    "\n",
    "### Demucs Issues:\n",
    "\n",
    "**If Demucs fails with \"Could not load libtorchcodec\":**\n",
    "```python\n",
    "# Run this in a new cell:\n",
    "!apt-get update && apt-get install -y ffmpeg\n",
    "# Then re-run the processing cell\n",
    "```\n",
    "\n",
    "**If Demucs is too slow:**\n",
    "- Use `CONFIG_STANDARD` instead of `CONFIG_FULL_WITH_DEMUCS`\n",
    "- Enable GPU in Colab: Runtime â†’ Change runtime type â†’ GPU\n",
    "\n",
    "**If memory issues:**\n",
    "- Process shorter audio segments\n",
    "- Use `CONFIG_STANDARD` (no Demucs)\n",
    "\n",
    "### Processing Tips:\n",
    "\n",
    "- **For most tracks:** Use `CONFIG_STANDARD` (fast, good results)\n",
    "- **For vocal isolation/remixes:** Use `CONFIG_FULL_WITH_DEMUCS`\n",
    "- **For already good tracks:** Use `CONFIG_CONSERVATIVE`\n",
    "- **For final polish only:** Use `CONFIG_MASTERING_ONLY`\n",
    "\n",
    "### Custom Configuration:\n",
    "\n",
    "You can create your own config by copying and modifying any preset:\n",
    "\n",
    "```python\n",
    "CONFIG_CUSTOM = {\n",
    "    'reduce_noise': True,\n",
    "    'noise_reduction_strength': 0.6,  # 0.0-1.0\n",
    "    'restore_frequencies': True,\n",
    "    'separate_stems': False,  # Set True to enable Demucs\n",
    "    'target_lufs': -14.0,  # -11 (loud) to -16 (quiet)\n",
    "    'master_eq': {\n",
    "        'bass': 1.0,      # -3.0 to +3.0 dB\n",
    "        'mid': 0.0,\n",
    "        'presence': 2.0,\n",
    "        'treble': 1.5\n",
    "    }\n",
    "}\n",
    "\n",
    "CONFIG = CONFIG_CUSTOM\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Documentation\n",
    "\n",
    "**GitHub Repository:** https://github.com/guitorte/musicas\n",
    "\n",
    "**Demucs:** State-of-the-art AI music source separation\n",
    "- Paper: https://arxiv.org/abs/2111.03600\n",
    "- Separates vocals, drums, bass, and other instruments\n",
    "- Requires FFmpeg and TorchCodec dependencies\n",
    "\n",
    "---\n",
    "\n",
    "**Made with â¤ï¸ for music producers**\n",
    "\n",
    "ğŸµ **100% Free â€¢ Professional Results â€¢ Demucs AI Integration** ğŸµ\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}