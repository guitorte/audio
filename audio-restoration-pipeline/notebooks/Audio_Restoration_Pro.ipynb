{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéµ Audio Restoration Pro\n",
    "\n",
    "## Princ√≠pio Central: \"First, Do No Harm\"\n",
    "\n",
    "Este notebook segue as melhores pr√°ticas da ind√∫stria baseadas em:\n",
    "- **Bob Katz** - \"Mastering Audio: The Art and the Science\"\n",
    "- **iZotope RX** - Padr√£o da ind√∫stria (2x Emmy Awards)\n",
    "- **IASA** - International Association of Sound and Audiovisual Archives\n",
    "\n",
    "---\n",
    "\n",
    "### Filosofia\n",
    "\n",
    "> \"√â f√°cil ir longe demais e fazer mais mal do que bem.\"\n",
    "\n",
    "### Workflow\n",
    "\n",
    "```\n",
    "1. AN√ÅLISE     ‚Üí Entender o problema antes de agir\n",
    "2. DECIS√ÉO     ‚Üí Cada etapa √© opcional e justificada\n",
    "3. PROCESSAR   ‚Üí M√≠nimo necess√°rio, m√∫ltiplos passes suaves\n",
    "4. VALIDAR     ‚Üí Comparar A/B, ouvir res√≠duo, verificar m√©tricas\n",
    "5. EXPORTAR    ‚Üí Preservar original, documentar processamento\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Etapa 0: Instala√ß√£o\n",
    "\n",
    "Instala apenas o necess√°rio. Demucs √© **opcional** e instalado separadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Bibliotecas essenciais\n",
    "!pip install -q librosa soundfile scipy numpy matplotlib ipywidgets noisereduce\n",
    "\n",
    "print(\"‚úì Instala√ß√£o completa!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Etapa 1: Conectar ao Google Drive e Selecionar Arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, Audio\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from datetime import datetime\n",
    "\n",
    "# Montar Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Configura√ß√£o de diret√≥rios\n",
    "INPUT_DIR = '/content/drive/MyDrive/00-restore'\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/00-restore/restored'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Entrada: {INPUT_DIR}\")\n",
    "print(f\"üìÅ Sa√≠da: {OUTPUT_DIR}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Buscar arquivos de √°udio\n",
    "audio_files = []\n",
    "for ext in ['*.mp3', '*.wav', '*.MP3', '*.WAV', '*.m4a', '*.flac', '*.aiff']:\n",
    "    audio_files.extend(glob.glob(os.path.join(INPUT_DIR, ext)))\n",
    "audio_files = sorted(set(audio_files))\n",
    "\n",
    "if not audio_files:\n",
    "    print(f\"‚ö†Ô∏è Nenhum arquivo encontrado em {INPUT_DIR}\")\n",
    "else:\n",
    "    print(f\"‚úì {len(audio_files)} arquivo(s) encontrado(s)\\n\")\n",
    "    \n",
    "    # Criar dropdown\n",
    "    options = [(f\"{Path(f).name} ({os.path.getsize(f)/1024/1024:.1f} MB)\", f) for f in audio_files]\n",
    "    \n",
    "    file_selector = widgets.Dropdown(\n",
    "        options=options,\n",
    "        description='Arquivo:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='90%')\n",
    "    )\n",
    "    \n",
    "    display(HTML(\"<h3>üéµ Selecione o arquivo para restaurar:</h3>\"))\n",
    "    display(file_selector)\n",
    "    \n",
    "    # Vari√°vel global\n",
    "    def get_selected_file():\n",
    "        return file_selector.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üî¨ Etapa 2: An√°lise Profunda\n",
    "\n",
    "**Princ√≠pio iZotope**: \"Sempre comece analisando o √°udio antes de qualquer processamento.\"\n",
    "\n",
    "Esta an√°lise ir√°:\n",
    "1. Medir SNR (Signal-to-Noise Ratio)\n",
    "2. Detectar clipping\n",
    "3. Analisar espectro de frequ√™ncias\n",
    "4. Medir loudness (LUFS)\n",
    "5. Avaliar dynamic range\n",
    "6. **Recomendar** processamentos (voc√™ decide se aplica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class AudioAnalyzer:\n",
    "    \"\"\"Analisador de √°udio seguindo princ√≠pios iZotope/Bob Katz\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, sr=44100):\n",
    "        self.file_path = file_path\n",
    "        self.filename = Path(file_path).name\n",
    "        self.sr = sr\n",
    "        \n",
    "        # Carregar √°udio\n",
    "        print(f\"üîç Carregando: {self.filename}\")\n",
    "        self.y, self.sr = librosa.load(file_path, sr=sr, mono=False)\n",
    "        \n",
    "        # Converter para mono para an√°lise\n",
    "        if self.y.ndim > 1:\n",
    "            self.y_mono = librosa.to_mono(self.y)\n",
    "            self.is_stereo = True\n",
    "        else:\n",
    "            self.y_mono = self.y\n",
    "            self.is_stereo = False\n",
    "        \n",
    "        self.duration = len(self.y_mono) / self.sr\n",
    "        self.analysis = {}\n",
    "        self.recommendations = []\n",
    "        \n",
    "    def analyze_all(self):\n",
    "        \"\"\"Executa todas as an√°lises\"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"üìä AN√ÅLISE COMPLETA DO √ÅUDIO\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        self._analyze_basic()\n",
    "        self._analyze_clipping()\n",
    "        self._analyze_noise()\n",
    "        self._analyze_frequency()\n",
    "        self._analyze_loudness()\n",
    "        self._analyze_dynamics()\n",
    "        self._generate_recommendations()\n",
    "        self._plot_analysis()\n",
    "        \n",
    "        return self.analysis, self.recommendations\n",
    "    \n",
    "    def _analyze_basic(self):\n",
    "        \"\"\"Informa√ß√µes b√°sicas\"\"\"\n",
    "        print(f\"\\nüìã INFORMA√á√ïES B√ÅSICAS\")\n",
    "        print(f\"   Arquivo: {self.filename}\")\n",
    "        print(f\"   Dura√ß√£o: {self.duration:.1f}s ({self.duration/60:.1f} min)\")\n",
    "        print(f\"   Sample Rate: {self.sr} Hz\")\n",
    "        print(f\"   Canais: {'Est√©reo' if self.is_stereo else 'Mono'}\")\n",
    "        \n",
    "        self.analysis['duration'] = self.duration\n",
    "        self.analysis['sample_rate'] = self.sr\n",
    "        self.analysis['is_stereo'] = self.is_stereo\n",
    "    \n",
    "    def _analyze_clipping(self):\n",
    "        \"\"\"Detectar clipping - PRIMEIRO passo segundo iZotope\"\"\"\n",
    "        print(f\"\\nüî¥ AN√ÅLISE DE CLIPPING\")\n",
    "        \n",
    "        # Detectar samples no limite\n",
    "        threshold = 0.99\n",
    "        clipped_samples = np.sum(np.abs(self.y_mono) >= threshold)\n",
    "        total_samples = len(self.y_mono)\n",
    "        clip_percentage = (clipped_samples / total_samples) * 100\n",
    "        \n",
    "        # Detectar sequ√™ncias de clipping (mais grave)\n",
    "        clipped_mask = np.abs(self.y_mono) >= threshold\n",
    "        clip_runs = np.diff(np.where(np.concatenate(([clipped_mask[0]], \n",
    "                                                      clipped_mask[:-1] != clipped_mask[1:], \n",
    "                                                      [True])))[0])[::2]\n",
    "        long_clips = np.sum(clip_runs > 3) if len(clip_runs) > 0 else 0\n",
    "        \n",
    "        peak = np.max(np.abs(self.y_mono))\n",
    "        peak_db = 20 * np.log10(peak + 1e-10)\n",
    "        \n",
    "        self.analysis['clipping'] = {\n",
    "            'percentage': clip_percentage,\n",
    "            'clipped_samples': clipped_samples,\n",
    "            'long_clips': long_clips,\n",
    "            'peak': peak,\n",
    "            'peak_db': peak_db\n",
    "        }\n",
    "        \n",
    "        if clip_percentage > 1:\n",
    "            print(f\"   ‚ö†Ô∏è  CLIPPING SEVERO: {clip_percentage:.2f}% dos samples\")\n",
    "            print(f\"   ‚ö†Ô∏è  {long_clips} sequ√™ncias longas de clipping\")\n",
    "        elif clip_percentage > 0.1:\n",
    "            print(f\"   ‚ö†Ô∏è  Clipping moderado: {clip_percentage:.3f}%\")\n",
    "        else:\n",
    "            print(f\"   ‚úì Sem clipping significativo\")\n",
    "        \n",
    "        print(f\"   Peak: {peak_db:.1f} dBFS\")\n",
    "    \n",
    "    def _analyze_noise(self):\n",
    "        \"\"\"Estimar n√≠vel de ru√≠do e SNR\"\"\"\n",
    "        print(f\"\\nüìâ AN√ÅLISE DE RU√çDO\")\n",
    "        \n",
    "        # Estimar noise floor usando percentis baixos\n",
    "        noise_floor = np.percentile(np.abs(self.y_mono), 5)\n",
    "        signal_level = np.percentile(np.abs(self.y_mono), 95)\n",
    "        \n",
    "        # SNR estimation\n",
    "        snr = 20 * np.log10((signal_level + 1e-10) / (noise_floor + 1e-10))\n",
    "        \n",
    "        # RMS do ru√≠do (primeiros 500ms se silenciosos, sen√£o percentil baixo)\n",
    "        first_samples = self.y_mono[:int(0.5 * self.sr)]\n",
    "        if np.max(np.abs(first_samples)) < 0.1:\n",
    "            noise_rms = np.sqrt(np.mean(first_samples**2))\n",
    "        else:\n",
    "            # Usar frames mais silenciosos\n",
    "            frame_size = 2048\n",
    "            frames = librosa.util.frame(self.y_mono, frame_length=frame_size, hop_length=frame_size//2)\n",
    "            frame_rms = np.sqrt(np.mean(frames**2, axis=0))\n",
    "            noise_rms = np.percentile(frame_rms, 10)\n",
    "        \n",
    "        noise_db = 20 * np.log10(noise_rms + 1e-10)\n",
    "        \n",
    "        self.analysis['noise'] = {\n",
    "            'snr': snr,\n",
    "            'noise_floor': noise_floor,\n",
    "            'noise_rms': noise_rms,\n",
    "            'noise_db': noise_db\n",
    "        }\n",
    "        \n",
    "        print(f\"   SNR estimado: {snr:.1f} dB\")\n",
    "        print(f\"   Noise floor: {noise_db:.1f} dBFS\")\n",
    "        \n",
    "        if snr < 15:\n",
    "            print(f\"   ‚ö†Ô∏è  RU√çDO ALTO - considere regravar se poss√≠vel\")\n",
    "        elif snr < 25:\n",
    "            print(f\"   ‚ö†Ô∏è  Ru√≠do moderado - redu√ß√£o suave recomendada\")\n",
    "        elif snr < 40:\n",
    "            print(f\"   üí° Ru√≠do leve - redu√ß√£o opcional\")\n",
    "        else:\n",
    "            print(f\"   ‚úì √Åudio limpo\")\n",
    "    \n",
    "    def _analyze_frequency(self):\n",
    "        \"\"\"Analisar espectro e detectar cortes de frequ√™ncia\"\"\"\n",
    "        print(f\"\\nüéº AN√ÅLISE ESPECTRAL\")\n",
    "        \n",
    "        # Calcular espectro\n",
    "        S = np.abs(librosa.stft(self.y_mono))\n",
    "        freqs = librosa.fft_frequencies(sr=self.sr)\n",
    "        \n",
    "        # Energia por banda\n",
    "        avg_spectrum = np.mean(S, axis=1)\n",
    "        \n",
    "        # Bandas de frequ√™ncia\n",
    "        bands = {\n",
    "            'sub_bass': (20, 60),\n",
    "            'bass': (60, 250),\n",
    "            'low_mid': (250, 500),\n",
    "            'mid': (500, 2000),\n",
    "            'high_mid': (2000, 4000),\n",
    "            'presence': (4000, 8000),\n",
    "            'brilliance': (8000, 16000),\n",
    "            'air': (16000, 22000)\n",
    "        }\n",
    "        \n",
    "        band_energy = {}\n",
    "        for name, (low, high) in bands.items():\n",
    "            mask = (freqs >= low) & (freqs < high)\n",
    "            if np.any(mask):\n",
    "                band_energy[name] = np.mean(avg_spectrum[mask])\n",
    "            else:\n",
    "                band_energy[name] = 0\n",
    "        \n",
    "        total = sum(band_energy.values())\n",
    "        band_percent = {k: (v/total)*100 for k, v in band_energy.items()}\n",
    "        \n",
    "        # Detectar corte de frequ√™ncias altas\n",
    "        high_freq_threshold = 8000\n",
    "        high_mask = freqs >= high_freq_threshold\n",
    "        high_energy = avg_spectrum[high_mask]\n",
    "        \n",
    "        # Encontrar onde energia cai significativamente\n",
    "        if len(high_energy) > 0:\n",
    "            normalized = high_energy / (np.max(avg_spectrum) + 1e-10)\n",
    "            cutoff_idx = np.where(normalized < 0.001)[0]\n",
    "            if len(cutoff_idx) > 0:\n",
    "                cutoff_freq = freqs[high_mask][cutoff_idx[0]]\n",
    "            else:\n",
    "                cutoff_freq = self.sr / 2\n",
    "        else:\n",
    "            cutoff_freq = self.sr / 2\n",
    "        \n",
    "        self.analysis['frequency'] = {\n",
    "            'band_energy': band_energy,\n",
    "            'band_percent': band_percent,\n",
    "            'high_freq_cutoff': cutoff_freq,\n",
    "            'has_high_freq_loss': cutoff_freq < 15000\n",
    "        }\n",
    "        \n",
    "        print(f\"   Distribui√ß√£o de energia:\")\n",
    "        print(f\"   Bass (60-250Hz):      {band_percent.get('bass', 0):.1f}%\")\n",
    "        print(f\"   Mids (500-2kHz):      {band_percent.get('mid', 0):.1f}%\")\n",
    "        print(f\"   Presence (4-8kHz):    {band_percent.get('presence', 0):.1f}%\")\n",
    "        print(f\"   Brilliance (8-16kHz): {band_percent.get('brilliance', 0):.1f}%\")\n",
    "        \n",
    "        if cutoff_freq < 15000:\n",
    "            print(f\"\\n   ‚ö†Ô∏è  Frequ√™ncias altas cortadas em ~{cutoff_freq:.0f} Hz\")\n",
    "            if cutoff_freq < 10000:\n",
    "                print(f\"   ‚ö†Ô∏è  Perda significativa - pode ser MP3 de baixa qualidade\")\n",
    "        else:\n",
    "            print(f\"\\n   ‚úì Espectro completo at√© {cutoff_freq:.0f} Hz\")\n",
    "    \n",
    "    def _analyze_loudness(self):\n",
    "        \"\"\"An√°lise de loudness (aproxima√ß√£o LUFS)\"\"\"\n",
    "        print(f\"\\nüîä AN√ÅLISE DE LOUDNESS\")\n",
    "        \n",
    "        # RMS (aproxima√ß√£o de loudness)\n",
    "        rms = np.sqrt(np.mean(self.y_mono**2))\n",
    "        \n",
    "        # Aproxima√ß√£o LUFS (simplificada - para LUFS real usar pyloudnorm)\n",
    "        # LUFS ‚âà 20*log10(RMS) + 0.691 (aproxima√ß√£o)\n",
    "        lufs_approx = 20 * np.log10(rms + 1e-10)\n",
    "        \n",
    "        self.analysis['loudness'] = {\n",
    "            'rms': rms,\n",
    "            'lufs_approx': lufs_approx\n",
    "        }\n",
    "        \n",
    "        print(f\"   LUFS (aproximado): {lufs_approx:.1f} dB\")\n",
    "        print(f\"   RMS: {rms:.4f}\")\n",
    "        \n",
    "        # Comparar com targets de streaming\n",
    "        print(f\"\\n   Compara√ß√£o com targets de streaming:\")\n",
    "        targets = {'Spotify/YouTube': -14, 'Apple Music': -16, 'Broadcast': -24}\n",
    "        for platform, target in targets.items():\n",
    "            diff = lufs_approx - target\n",
    "            if abs(diff) < 2:\n",
    "                print(f\"   ‚úì {platform} ({target} LUFS): OK\")\n",
    "            elif diff > 0:\n",
    "                print(f\"   ‚ö†Ô∏è  {platform} ({target} LUFS): {diff:+.1f} dB mais alto\")\n",
    "            else:\n",
    "                print(f\"   üí° {platform} ({target} LUFS): {diff:+.1f} dB mais baixo\")\n",
    "    \n",
    "    def _analyze_dynamics(self):\n",
    "        \"\"\"An√°lise de dynamic range\"\"\"\n",
    "        print(f\"\\nüìà AN√ÅLISE DE DIN√ÇMICA\")\n",
    "        \n",
    "        # Peak vs RMS\n",
    "        peak = np.max(np.abs(self.y_mono))\n",
    "        rms = np.sqrt(np.mean(self.y_mono**2))\n",
    "        crest_factor = 20 * np.log10(peak / (rms + 1e-10))\n",
    "        \n",
    "        # Dynamic range estimation (diferen√ßa entre partes mais altas e mais baixas)\n",
    "        frame_size = 2048\n",
    "        frames = librosa.util.frame(self.y_mono, frame_length=frame_size, hop_length=frame_size//2)\n",
    "        frame_rms = np.sqrt(np.mean(frames**2, axis=0))\n",
    "        \n",
    "        # Ignorar sil√™ncio\n",
    "        non_silent = frame_rms > np.percentile(frame_rms, 10)\n",
    "        if np.any(non_silent):\n",
    "            loud_rms = np.percentile(frame_rms[non_silent], 95)\n",
    "            quiet_rms = np.percentile(frame_rms[non_silent], 20)\n",
    "            dynamic_range = 20 * np.log10((loud_rms + 1e-10) / (quiet_rms + 1e-10))\n",
    "        else:\n",
    "            dynamic_range = 0\n",
    "        \n",
    "        self.analysis['dynamics'] = {\n",
    "            'crest_factor': crest_factor,\n",
    "            'dynamic_range': dynamic_range\n",
    "        }\n",
    "        \n",
    "        print(f\"   Crest Factor: {crest_factor:.1f} dB\")\n",
    "        print(f\"   Dynamic Range: {dynamic_range:.1f} dB\")\n",
    "        \n",
    "        if crest_factor < 6:\n",
    "            print(f\"   ‚ö†Ô∏è  Muito comprimido (loudness war)\")\n",
    "        elif crest_factor < 10:\n",
    "            print(f\"   üí° Compress√£o moderada\")\n",
    "        else:\n",
    "            print(f\"   ‚úì Boa din√¢mica preservada\")\n",
    "    \n",
    "    def _generate_recommendations(self):\n",
    "        \"\"\"Gera recomenda√ß√µes baseadas na an√°lise\"\"\"\n",
    "        print(f\"\\n\" + \"=\"*70)\n",
    "        print(\"üìã RECOMENDA√á√ïES\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        self.recommendations = []\n",
    "        \n",
    "        # 1. Clipping\n",
    "        clip = self.analysis['clipping']\n",
    "        if clip['percentage'] > 0.5:\n",
    "            self.recommendations.append({\n",
    "                'priority': 'ALTA',\n",
    "                'step': 'de-clip',\n",
    "                'reason': f\"Clipping detectado ({clip['percentage']:.2f}%)\",\n",
    "                'action': 'Aplicar de-clipping ANTES de qualquer outro processamento'\n",
    "            })\n",
    "        \n",
    "        # 2. Ru√≠do\n",
    "        noise = self.analysis['noise']\n",
    "        if noise['snr'] < 20:\n",
    "            self.recommendations.append({\n",
    "                'priority': 'ALTA',\n",
    "                'step': 'noise-reduction',\n",
    "                'reason': f\"SNR baixo ({noise['snr']:.1f} dB)\",\n",
    "                'action': 'Redu√ß√£o de ru√≠do moderada (0.4-0.6)',\n",
    "                'warning': 'Se SNR < 10dB, considere regravar'\n",
    "            })\n",
    "        elif noise['snr'] < 30:\n",
    "            self.recommendations.append({\n",
    "                'priority': 'M√âDIA',\n",
    "                'step': 'noise-reduction',\n",
    "                'reason': f\"Ru√≠do moderado (SNR: {noise['snr']:.1f} dB)\",\n",
    "                'action': 'Redu√ß√£o de ru√≠do suave (0.2-0.4)'\n",
    "            })\n",
    "        \n",
    "        # 3. Frequ√™ncias\n",
    "        freq = self.analysis['frequency']\n",
    "        if freq['has_high_freq_loss'] and freq['high_freq_cutoff'] < 12000:\n",
    "            self.recommendations.append({\n",
    "                'priority': 'BAIXA',\n",
    "                'step': 'frequency-restoration',\n",
    "                'reason': f\"Frequ√™ncias cortadas em {freq['high_freq_cutoff']:.0f} Hz\",\n",
    "                'action': 'Excita√ß√£o de harm√¥nicos (sutil)',\n",
    "                'warning': 'N√ÉO √© poss√≠vel recriar frequ√™ncias perdidas - apenas excitar harm√¥nicos existentes'\n",
    "            })\n",
    "        \n",
    "        # 4. Loudness\n",
    "        loud = self.analysis['loudness']\n",
    "        if loud['lufs_approx'] < -20:\n",
    "            self.recommendations.append({\n",
    "                'priority': 'M√âDIA',\n",
    "                'step': 'normalize',\n",
    "                'reason': f\"√Åudio muito baixo ({loud['lufs_approx']:.1f} LUFS)\",\n",
    "                'action': 'Normalizar para -14 LUFS (Spotify/YouTube)'\n",
    "            })\n",
    "        elif loud['lufs_approx'] > -10:\n",
    "            self.recommendations.append({\n",
    "                'priority': 'BAIXA',\n",
    "                'step': 'check-dynamics',\n",
    "                'reason': f\"√Åudio muito alto ({loud['lufs_approx']:.1f} LUFS)\",\n",
    "                'action': 'Verificar se din√¢mica foi preservada'\n",
    "            })\n",
    "        \n",
    "        # Mostrar recomenda√ß√µes\n",
    "        if not self.recommendations:\n",
    "            print(\"\\n‚úì √Åudio em bom estado! Processamento m√≠nimo recomendado.\")\n",
    "            print(\"  Considere apenas normaliza√ß√£o para target de streaming.\")\n",
    "        else:\n",
    "            for i, rec in enumerate(self.recommendations, 1):\n",
    "                priority_icon = {'ALTA': 'üî¥', 'M√âDIA': 'üü°', 'BAIXA': 'üü¢'}[rec['priority']]\n",
    "                print(f\"\\n{priority_icon} [{rec['priority']}] {rec['step'].upper()}\")\n",
    "                print(f\"   Motivo: {rec['reason']}\")\n",
    "                print(f\"   A√ß√£o: {rec['action']}\")\n",
    "                if 'warning' in rec:\n",
    "                    print(f\"   ‚ö†Ô∏è  {rec['warning']}\")\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*70)\n",
    "        print(\"üí° LEMBRE-SE: Cada processamento √© OPCIONAL.\")\n",
    "        print(\"   Se o √°udio j√° est√° bom, n√£o processe!\")\n",
    "        print(\"=\"*70)\n",
    "    \n",
    "    def _plot_analysis(self):\n",
    "        \"\"\"Visualiza√ß√£o do √°udio\"\"\"\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "        \n",
    "        # 1. Waveform\n",
    "        times = np.arange(len(self.y_mono)) / self.sr\n",
    "        axes[0].plot(times, self.y_mono, color='steelblue', linewidth=0.5)\n",
    "        axes[0].axhline(y=0.99, color='red', linestyle='--', alpha=0.5, label='Clip threshold')\n",
    "        axes[0].axhline(y=-0.99, color='red', linestyle='--', alpha=0.5)\n",
    "        axes[0].set_title('Waveform', fontsize=12, fontweight='bold')\n",
    "        axes[0].set_xlabel('Tempo (s)')\n",
    "        axes[0].set_ylabel('Amplitude')\n",
    "        axes[0].legend(loc='upper right')\n",
    "        axes[0].set_xlim(0, self.duration)\n",
    "        \n",
    "        # 2. Spectrogram\n",
    "        D = librosa.amplitude_to_db(np.abs(librosa.stft(self.y_mono)), ref=np.max)\n",
    "        img = librosa.display.specshow(D, sr=self.sr, x_axis='time', y_axis='log', ax=axes[1], cmap='magma')\n",
    "        axes[1].set_title('Espectrograma', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Marcar cutoff de frequ√™ncia se houver\n",
    "        if self.analysis['frequency']['has_high_freq_loss']:\n",
    "            cutoff = self.analysis['frequency']['high_freq_cutoff']\n",
    "            axes[1].axhline(y=cutoff, color='cyan', linestyle='--', alpha=0.7, label=f'Cutoff ~{cutoff:.0f}Hz')\n",
    "            axes[1].legend(loc='upper right')\n",
    "        \n",
    "        fig.colorbar(img, ax=axes[1], format='%+2.0f dB')\n",
    "        \n",
    "        # 3. Espectro m√©dio\n",
    "        S = np.abs(librosa.stft(self.y_mono))\n",
    "        freqs = librosa.fft_frequencies(sr=self.sr)\n",
    "        avg_spectrum = np.mean(S, axis=1)\n",
    "        avg_spectrum_db = 20 * np.log10(avg_spectrum + 1e-10)\n",
    "        \n",
    "        axes[2].semilogx(freqs[1:], avg_spectrum_db[1:], color='steelblue', linewidth=1)\n",
    "        axes[2].set_title('Espectro M√©dio', fontsize=12, fontweight='bold')\n",
    "        axes[2].set_xlabel('Frequ√™ncia (Hz)')\n",
    "        axes[2].set_ylabel('Magnitude (dB)')\n",
    "        axes[2].set_xlim(20, self.sr/2)\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Marcar bandas importantes\n",
    "        for freq, label in [(250, 'Bass'), (2000, 'Mid'), (8000, 'Presence')]:\n",
    "            axes[2].axvline(x=freq, color='gray', linestyle=':', alpha=0.5)\n",
    "            axes[2].text(freq, axes[2].get_ylim()[1]-5, label, fontsize=8, ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('/content/analysis.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(\"\\nüìä Visualiza√ß√£o salva em /content/analysis.png\")\n",
    "\n",
    "# Executar an√°lise\n",
    "if 'file_selector' in dir():\n",
    "    analyzer = AudioAnalyzer(get_selected_file())\n",
    "    analysis, recommendations = analyzer.analyze_all()\n",
    "    \n",
    "    # Guardar para uso posterior\n",
    "    AUDIO_ANALYSIS = analysis\n",
    "    AUDIO_RECOMMENDATIONS = recommendations\n",
    "    ORIGINAL_AUDIO = analyzer.y_mono\n",
    "    SAMPLE_RATE = analyzer.sr\n",
    "    \n",
    "    print(\"\\nüéß Ou√ßa o √°udio original:\")\n",
    "    display(Audio(analyzer.y_mono, rate=analyzer.sr))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Execute a Etapa 1 primeiro para selecionar um arquivo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Etapa 3: Processamento Modular\n",
    "\n",
    "Cada m√≥dulo √© **independente** e **opcional**. \n",
    "\n",
    "**Ordem recomendada (iZotope)**:\n",
    "1. De-clip (se necess√°rio)\n",
    "2. Redu√ß√£o de ru√≠do (se necess√°rio)\n",
    "3. EQ corretivo (se necess√°rio)\n",
    "4. Normaliza√ß√£o (quase sempre)\n",
    "\n",
    "### ‚ö†Ô∏è Regras de Ouro:\n",
    "- **Menos √© mais**: Use configura√ß√µes m√≠nimas\n",
    "- **Ou√ßa o res√≠duo**: Se ouvir m√∫sica, est√° removendo demais\n",
    "- **Compare sempre**: A/B entre original e processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioProcessor:\n",
    "    \"\"\"Processador de √°udio modular seguindo princ√≠pios 'First, Do No Harm'\"\"\"\n",
    "    \n",
    "    def __init__(self, audio, sr):\n",
    "        self.original = audio.copy()\n",
    "        self.current = audio.copy()\n",
    "        self.sr = sr\n",
    "        self.history = [('original', audio.copy())]\n",
    "        self.residues = {}  # Para ouvir o que foi removido\n",
    "    \n",
    "    def get_current(self):\n",
    "        return self.current.copy()\n",
    "    \n",
    "    def undo(self):\n",
    "        \"\"\"Desfaz √∫ltima opera√ß√£o\"\"\"\n",
    "        if len(self.history) > 1:\n",
    "            self.history.pop()\n",
    "            self.current = self.history[-1][1].copy()\n",
    "            print(f\"‚Ü©Ô∏è Desfeito. Estado atual: {self.history[-1][0]}\")\n",
    "        else:\n",
    "            print(\"Nada para desfazer.\")\n",
    "    \n",
    "    def reduce_noise(self, strength=0.3, stationary=True):\n",
    "        \"\"\"\n",
    "        Redu√ß√£o de ru√≠do conservadora.\n",
    "        \n",
    "        Args:\n",
    "            strength: 0.1 (sutil) a 1.0 (agressivo). Recomendado: 0.2-0.4\n",
    "            stationary: True para ru√≠do constante (HVAC, hiss)\n",
    "        \"\"\"\n",
    "        import noisereduce as nr\n",
    "        \n",
    "        print(f\"\\nüîá Aplicando redu√ß√£o de ru√≠do (strength={strength})\")\n",
    "        print(f\"   Modo: {'Estacion√°rio' if stationary else 'N√£o-estacion√°rio'}\")\n",
    "        \n",
    "        # Aplicar redu√ß√£o\n",
    "        reduced = nr.reduce_noise(\n",
    "            y=self.current,\n",
    "            sr=self.sr,\n",
    "            prop_decrease=strength,\n",
    "            stationary=stationary,\n",
    "            n_fft=2048,\n",
    "            hop_length=512\n",
    "        )\n",
    "        \n",
    "        # Calcular res√≠duo (o que foi removido)\n",
    "        residue = self.current - reduced\n",
    "        self.residues['noise'] = residue\n",
    "        \n",
    "        # M√©tricas\n",
    "        residue_energy = np.sqrt(np.mean(residue**2))\n",
    "        original_energy = np.sqrt(np.mean(self.current**2))\n",
    "        removed_percent = (residue_energy / original_energy) * 100\n",
    "        \n",
    "        print(f\"   ‚úì Removido: {removed_percent:.1f}% da energia\")\n",
    "        \n",
    "        if removed_percent > 20:\n",
    "            print(f\"   ‚ö†Ô∏è  ATEN√á√ÉO: Muita energia removida! Considere reduzir strength.\")\n",
    "        \n",
    "        # Atualizar\n",
    "        self.current = reduced\n",
    "        self.history.append((f'noise_reduction_{strength}', reduced.copy()))\n",
    "        \n",
    "        print(f\"   üí° Use player.listen_residue('noise') para ouvir o que foi removido\")\n",
    "    \n",
    "    def normalize(self, target_db=-14.0, true_peak=-1.0):\n",
    "        \"\"\"\n",
    "        Normaliza√ß√£o para target LUFS com prote√ß√£o de true peak.\n",
    "        \n",
    "        Args:\n",
    "            target_db: Target em dB (aproxima√ß√£o LUFS). -14 = Spotify/YouTube\n",
    "            true_peak: Limite m√°ximo. -1.0 √© padr√£o da ind√∫stria\n",
    "        \"\"\"\n",
    "        print(f\"\\nüîä Normalizando para {target_db} dB (true peak: {true_peak} dB)\")\n",
    "        \n",
    "        # Calcular loudness atual\n",
    "        current_rms = np.sqrt(np.mean(self.current**2))\n",
    "        current_db = 20 * np.log10(current_rms + 1e-10)\n",
    "        \n",
    "        # Calcular ganho necess√°rio\n",
    "        gain_db = target_db - current_db\n",
    "        gain_linear = 10 ** (gain_db / 20)\n",
    "        \n",
    "        # Aplicar ganho\n",
    "        normalized = self.current * gain_linear\n",
    "        \n",
    "        # Verificar true peak\n",
    "        peak = np.max(np.abs(normalized))\n",
    "        peak_db = 20 * np.log10(peak + 1e-10)\n",
    "        \n",
    "        if peak_db > true_peak:\n",
    "            # Limitar para respeitar true peak\n",
    "            reduction_db = peak_db - true_peak\n",
    "            reduction_linear = 10 ** (-reduction_db / 20)\n",
    "            normalized = normalized * reduction_linear\n",
    "            print(f\"   ‚ö†Ô∏è  Peak excedia limite. Reduzido em {reduction_db:.1f} dB\")\n",
    "        \n",
    "        # Soft clipping para seguran√ßa\n",
    "        normalized = np.tanh(normalized * 0.95) / 0.95\n",
    "        \n",
    "        # M√©tricas finais\n",
    "        final_rms = np.sqrt(np.mean(normalized**2))\n",
    "        final_db = 20 * np.log10(final_rms + 1e-10)\n",
    "        final_peak = 20 * np.log10(np.max(np.abs(normalized)) + 1e-10)\n",
    "        \n",
    "        print(f\"   Antes: {current_db:.1f} dB\")\n",
    "        print(f\"   Depois: {final_db:.1f} dB\")\n",
    "        print(f\"   Peak: {final_peak:.1f} dBFS\")\n",
    "        print(f\"   ‚úì Ganho aplicado: {gain_db:+.1f} dB\")\n",
    "        \n",
    "        self.current = normalized\n",
    "        self.history.append((f'normalize_{target_db}', normalized.copy()))\n",
    "    \n",
    "    def apply_eq(self, bass=0, mid=0, presence=0, treble=0):\n",
    "        \"\"\"\n",
    "        EQ simples e suave.\n",
    "        \n",
    "        Args:\n",
    "            bass: -6 a +6 dB (centrado em 100Hz)\n",
    "            mid: -6 a +6 dB (centrado em 1kHz)\n",
    "            presence: -6 a +6 dB (centrado em 4kHz)\n",
    "            treble: -6 a +6 dB (centrado em 10kHz)\n",
    "        \"\"\"\n",
    "        from scipy import signal\n",
    "        \n",
    "        print(f\"\\nüéõÔ∏è Aplicando EQ: bass={bass:+.1f}, mid={mid:+.1f}, presence={presence:+.1f}, treble={treble:+.1f}\")\n",
    "        \n",
    "        result = self.current.copy()\n",
    "        \n",
    "        # Bandas de EQ\n",
    "        bands = [\n",
    "            ('bass', 100, bass),\n",
    "            ('mid', 1000, mid),\n",
    "            ('presence', 4000, presence),\n",
    "            ('treble', 10000, treble)\n",
    "        ]\n",
    "        \n",
    "        for name, freq, gain_db in bands:\n",
    "            if abs(gain_db) > 0.1:  # S√≥ aplica se ganho significativo\n",
    "                # Peak filter\n",
    "                Q = 1.0  # Largura de banda moderada\n",
    "                w0 = freq / (self.sr / 2)\n",
    "                \n",
    "                if w0 < 1.0:  # Frequ√™ncia v√°lida\n",
    "                    A = 10 ** (gain_db / 40)\n",
    "                    alpha = np.sin(np.pi * w0) / (2 * Q)\n",
    "                    \n",
    "                    b0 = 1 + alpha * A\n",
    "                    b1 = -2 * np.cos(np.pi * w0)\n",
    "                    b2 = 1 - alpha * A\n",
    "                    a0 = 1 + alpha / A\n",
    "                    a1 = -2 * np.cos(np.pi * w0)\n",
    "                    a2 = 1 - alpha / A\n",
    "                    \n",
    "                    b = [b0/a0, b1/a0, b2/a0]\n",
    "                    a = [1, a1/a0, a2/a0]\n",
    "                    \n",
    "                    result = signal.filtfilt(b, a, result)\n",
    "        \n",
    "        self.current = result\n",
    "        self.history.append((f'eq', result.copy()))\n",
    "        print(f\"   ‚úì EQ aplicado\")\n",
    "    \n",
    "    def listen_residue(self, step_name):\n",
    "        \"\"\"Ouvir o que foi removido em determinada etapa\"\"\"\n",
    "        if step_name in self.residues:\n",
    "            print(f\"üîç Res√≠duo de '{step_name}' (o que foi REMOVIDO):\")\n",
    "            print(\"   Se ouvir m√∫sica clara aqui, a configura√ß√£o estava muito agressiva!\")\n",
    "            return Audio(self.residues[step_name], rate=self.sr)\n",
    "        else:\n",
    "            print(f\"Res√≠duo '{step_name}' n√£o encontrado.\")\n",
    "            print(f\"Dispon√≠veis: {list(self.residues.keys())}\")\n",
    "    \n",
    "    def compare(self):\n",
    "        \"\"\"Compara√ß√£o A/B entre original e processado\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üéß COMPARA√á√ÉO A/B\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(\"\\nüî¥ ORIGINAL:\")\n",
    "        display(Audio(self.original, rate=self.sr))\n",
    "        \n",
    "        print(\"\\nüü¢ PROCESSADO:\")\n",
    "        display(Audio(self.current, rate=self.sr))\n",
    "        \n",
    "        # M√©tricas comparativas\n",
    "        orig_rms = np.sqrt(np.mean(self.original**2))\n",
    "        proc_rms = np.sqrt(np.mean(self.current**2))\n",
    "        \n",
    "        print(f\"\\nüìä M√©tricas:\")\n",
    "        print(f\"   Original - RMS: {20*np.log10(orig_rms+1e-10):.1f} dB, Peak: {20*np.log10(np.max(np.abs(self.original))+1e-10):.1f} dBFS\")\n",
    "        print(f\"   Processado - RMS: {20*np.log10(proc_rms+1e-10):.1f} dB, Peak: {20*np.log10(np.max(np.abs(self.current))+1e-10):.1f} dBFS\")\n",
    "        \n",
    "        print(f\"\\nüí° Ou√ßa com aten√ß√£o:\")\n",
    "        print(f\"   - O processado soa MELHOR ou apenas DIFERENTE?\")\n",
    "        print(f\"   - H√° artefatos (chiados, distor√ß√£o)?\")\n",
    "        print(f\"   - A naturalidade foi preservada?\")\n",
    "\n",
    "# Criar processador\n",
    "if 'ORIGINAL_AUDIO' in dir():\n",
    "    processor = AudioProcessor(ORIGINAL_AUDIO, SAMPLE_RATE)\n",
    "    print(\"‚úì Processador criado!\")\n",
    "    print(\"\\nComandos dispon√≠veis:\")\n",
    "    print(\"  processor.reduce_noise(strength=0.3)  # Redu√ß√£o de ru√≠do\")\n",
    "    print(\"  processor.normalize(target_db=-14)    # Normaliza√ß√£o\")\n",
    "    print(\"  processor.apply_eq(bass=0, mid=0, presence=1, treble=0)  # EQ\")\n",
    "    print(\"  processor.compare()                   # Comparar A/B\")\n",
    "    print(\"  processor.listen_residue('noise')     # Ouvir o que foi removido\")\n",
    "    print(\"  processor.undo()                      # Desfazer √∫ltima opera√ß√£o\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Execute a an√°lise primeiro (Etapa 2).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Redu√ß√£o de Ru√≠do (se recomendado)\n",
    "\n",
    "**Regra**: Use o valor M√çNIMO que resolve o problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste o valor de strength conforme necess√°rio\n",
    "# 0.1-0.2 = sutil (recomendado para come√ßar)\n",
    "# 0.3-0.4 = moderado\n",
    "# 0.5+ = agressivo (cuidado com artefatos!)\n",
    "\n",
    "processor.reduce_noise(strength=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE: Ou√ßa o res√≠duo!\n",
    "# Se ouvir m√∫sica clara aqui, est√° removendo demais!\n",
    "display(processor.listen_residue('noise'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 EQ Corretivo (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EQ suave - valores em dB (-6 a +6)\n",
    "# Deixe em 0 as bandas que n√£o precisam de ajuste\n",
    "\n",
    "processor.apply_eq(\n",
    "    bass=0,       # 100Hz\n",
    "    mid=0,        # 1kHz  \n",
    "    presence=0.5, # 4kHz - adiciona clareza\n",
    "    treble=0      # 10kHz\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Normaliza√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets comuns:\n",
    "# -14 dB = Spotify, YouTube, Tidal\n",
    "# -16 dB = Apple Music\n",
    "# -24 dB = Broadcast (TV/R√°dio)\n",
    "\n",
    "processor.normalize(target_db=-14.0, true_peak=-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéß Etapa 4: Compara√ß√£o Final A/B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.compare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desfazer se necess√°rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se n√£o ficou bom, desfa√ßa:\n",
    "# processor.undo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíæ Etapa 5: Exportar\n",
    "\n",
    "Salva o arquivo processado preservando o original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar nome do arquivo de sa√≠da\n",
    "input_name = Path(get_selected_file()).stem\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_filename = f\"{input_name}_restored_{timestamp}.wav\"\n",
    "output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
    "\n",
    "# Salvar\n",
    "sf.write(output_path, processor.current, processor.sr, subtype='PCM_24')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úì ARQUIVO SALVO!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìÅ Localiza√ß√£o: {output_path}\")\n",
    "print(f\"üìä Formato: WAV 24-bit\")\n",
    "print(f\"üéµ Sample Rate: {processor.sr} Hz\")\n",
    "\n",
    "# Tamanho do arquivo\n",
    "size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "print(f\"üíæ Tamanho: {size_mb:.1f} MB\")\n",
    "\n",
    "print(f\"\\n‚úì Original preservado em: {get_selected_file()}\")\n",
    "\n",
    "# Log do processamento\n",
    "print(f\"\\nüìã Hist√≥rico de processamento:\")\n",
    "for i, (step, _) in enumerate(processor.history):\n",
    "    print(f\"   {i}. {step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé∏ Etapa Extra: Separa√ß√£o de Stems (Demucs)\n",
    "\n",
    "### ‚ö†Ô∏è ATEN√á√ÉO - Leia antes de usar:\n",
    "\n",
    "**Demucs N√ÉO deve ser usado para restaura√ß√£o geral!**\n",
    "\n",
    "Use APENAS se voc√™ precisa:\n",
    "- Isolar vocais para remix\n",
    "- Extrair bateria ou baixo separadamente\n",
    "- Remover um instrumento espec√≠fico\n",
    "\n",
    "**Problemas conhecidos:**\n",
    "- Introduz artefatos de separa√ß√£o\n",
    "- Stem \"other\" frequentemente tem problemas\n",
    "- Pode alterar a tonalidade entre segmentos\n",
    "- O reposit√≥rio original **n√£o √© mais mantido**\n",
    "\n",
    "Se seu objetivo √© apenas **melhorar a qualidade geral**, N√ÉO use Demucs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar Demucs (apenas se necess√°rio)\n",
    "# !pip install -q demucs torchaudio\n",
    "\n",
    "print(\"‚ö†Ô∏è Demucs n√£o instalado por padr√£o.\")\n",
    "print(\"Para instalar, descomente a linha acima e execute.\")\n",
    "print(\"\\nLembre-se: Use apenas se REALMENTE precisar de stems separados!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Refer√™ncias\n",
    "\n",
    "Este notebook foi constru√≠do seguindo:\n",
    "\n",
    "1. **Bob Katz** - \"Mastering Audio: The Art and the Science\"\n",
    "   - K-System para medi√ß√£o de loudness\n",
    "   - Foco em RMS ao inv√©s de picos\n",
    "\n",
    "2. **iZotope RX** - Order of Operations\n",
    "   - An√°lise primeiro, a√ß√£o depois\n",
    "   - Clipping ‚Üí Ru√≠do steady-state ‚Üí Ru√≠do complexo ‚Üí EQ ‚Üí Normaliza√ß√£o\n",
    "\n",
    "3. **IASA** - International Association of Sound and Audiovisual Archives\n",
    "   - \"Evitar ou minimizar perda de dados\"\n",
    "   - \"Transfer√™ncias sem altera√ß√µes subjetivas\"\n",
    "\n",
    "4. **Padr√µes de Streaming (2025)**\n",
    "   - Spotify/YouTube: -14 LUFS, True Peak -1 dBTP\n",
    "   - Apple Music: -16 LUFS\n",
    "\n",
    "---\n",
    "\n",
    "**Princ√≠pio Final**: \"Se n√£o est√° quebrado, n√£o conserte.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
