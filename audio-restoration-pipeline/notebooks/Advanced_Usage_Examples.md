# ğŸ“š Exemplos AvanÃ§ados de Uso - Google Colab

## Ãndice RÃ¡pido
1. [Interface Interativa](#1-interface-interativa)
2. [Auto-ConfiguraÃ§Ã£o Inteligente](#2-auto-configuraÃ§Ã£o-inteligente)
3. [Processamento AvanÃ§ado Manual](#3-processamento-avanÃ§ado-manual)
4. [Workflow Profissional Completo](#4-workflow-profissional-completo)

---

## 1. Interface Interativa

### Uso BÃ¡sico

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURAÃ‡ÃƒO VISUAL COM WIDGETS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from modules import create_quick_config

# Criar interface
CONFIG = create_quick_config()

# Processar com configuraÃ§Ã£o criada
result = pipeline.process_audio(
    audio_files[0],
    config=CONFIG
)
```

### PersonalizaÃ§Ã£o AvanÃ§ada

```python
# Criar interface e armazenar objeto
from modules import InteractiveConfig

interface = InteractiveConfig()
config = interface.create_interface()

# Modificar manualmente apÃ³s interface
config['advanced'] = {
    'multiband_compress': True,
    'de_esser': True
}

# Processar
result = pipeline.process_audio(audio_file, config=config)
```

---

## 2. Auto-ConfiguraÃ§Ã£o Inteligente

### Uso Simples

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AUTO-CONFIGURAÃ‡ÃƒO BASEADA EM ANÃLISE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from modules import auto_configure, SpectralAnalyzer

# 1. Analisar Ã¡udio
analyzer = SpectralAnalyzer()
analysis = analyzer.analyze_audio(test_file)

# 2. Gerar configuraÃ§Ã£o inteligente
config = auto_configure(analysis, verbose=True)

# 3. Processar
result = pipeline.process_audio(test_file, config=config)
```

### AnÃ¡lise em Batch

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANÃLISE E CONFIGURAÃ‡ÃƒO AUTOMÃTICA PARA MÃšLTIPLOS ARQUIVOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

analyzer = SpectralAnalyzer()
configs = {}

# Gerar configuraÃ§Ã£o especÃ­fica para cada arquivo
for audio_file in audio_files:
    analysis = analyzer.analyze_audio(audio_file)
    configs[audio_file] = auto_configure(analysis, verbose=False)

# Processar cada um com sua configuraÃ§Ã£o otimizada
for audio_file, config in configs.items():
    print(f"\n{'='*60}")
    print(f"Processando: {Path(audio_file).name}")
    print(f"ConfiguraÃ§Ã£o: {config['_metadata']['recommended_preset'].upper()}")
    print(f"{'='*60}")

    result = pipeline.process_audio(audio_file, config=config)
```

### AnÃ¡lise Comparativa

```python
# Comparar diferentes estratÃ©gias
strategies = {
    'Auto': auto_configure(analysis, verbose=False),
    'Suave': CONFIG_SUAVE,
    'Agressivo': CONFIG_AGRESSIVO,
    'Demucs': CONFIG_DEMUCS
}

results = {}
for name, config in strategies.items():
    print(f"\n Processando com: {name}")
    results[name] = pipeline.process_audio(
        test_file,
        output_name=f"{Path(test_file).stem}_{name}",
        config=config
    )
```

---

## 3. Processamento AvanÃ§ado Manual

### CompressÃ£o Multi-Banda

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COMPRESSÃƒO MULTI-BANDA PROFISSIONAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

from modules import AdvancedAudioProcessor
import librosa
import soundfile as sf

processor = AdvancedAudioProcessor(sr=44100)

# Carregar Ã¡udio
y, sr = librosa.load(test_file, sr=44100)

# CompressÃ£o multi-banda
y_compressed = processor.multiband_compress(
    y, sr,
    bands=[
        (20, 200),      # Low - para punch de kick/bass
        (200, 1000),    # Low-Mid - para body de instrumentos
        (1000, 5000),   # Mid-High - para vocais
        (5000, 20000)   # High - para brilho
    ],
    ratios=[3.0, 4.0, 3.0, 2.0],  # Mais compressÃ£o nos mÃ©dios
    thresholds=[-24, -20, -18, -20]
)

# Salvar
output_path = '/content/multiband_compressed.wav'
sf.write(output_path, y_compressed, sr)

print(f"âœ“ Salvo: {output_path}")
display(Audio(output_path))
```

### De-Esser para Vocais

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DE-ESSER PROFISSIONAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Processar com stems primeiro para separar vocal
config_stems = {
    'separate_stems': True,
    'stem_separation_model': 'demucs'
}

result = pipeline.process_audio(test_file, config=config_stems)

# Pegar vocal separado
vocal_path = result['stages']['stem_separation']['vocals']
y_vocal, sr = librosa.load(vocal_path, sr=44100)

# Aplicar de-esser
processor = AdvancedAudioProcessor()
y_deessed = processor.de_esser(
    y_vocal, sr,
    freq_range=(5000, 8000),  # Range de sibilÃ¢ncia
    threshold_db=-15,
    ratio=4.0
)

# Salvar
output_path = '/content/vocal_deessed.wav'
sf.write(output_path, y_deessed, sr)

print("ğŸ¤ ANTES (com sibilÃ¢ncia):")
display(Audio(vocal_path))

print("\nğŸ¤ DEPOIS (de-essed):")
display(Audio(output_path))
```

### Exciter HarmÃ´nico

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXCITER HARMÃ”NICO - Adicionar brilho e "warmth"
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

y, sr = librosa.load(test_file, sr=44100)

processor = AdvancedAudioProcessor()

# Exciter suave
y_excited = processor.harmonic_exciter(
    y, sr,
    drive=0.3,   # Quantidade de distorÃ§Ã£o harmÃ´nica
    mix=0.2      # 20% wet, 80% dry
)

# Salvar
output_path = '/content/with_exciter.wav'
sf.write(output_path, y_excited, sr)

print("ğŸ”Š ORIGINAL:")
display(Audio(test_file))

print("\nâœ¨ COM EXCITER:")
display(Audio(output_path))
```

### Transient Shaper para Bateria

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TRANSIENT SHAPER - Mais punch na bateria
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Separar bateria primeiro
result = pipeline.process_audio(test_file, config={'separate_stems': True})
drums_path = result['stages']['stem_separation']['drums']

y_drums, sr = librosa.load(drums_path, sr=44100)

# Aplicar transient shaper
processor = AdvancedAudioProcessor()
y_shaped = processor.transient_shaper(
    y_drums, sr,
    attack_gain=1.5,    # Mais punch nos ataques
    sustain_gain=0.7    # Sustain mais seco
)

# Salvar
output_path = '/content/drums_shaped.wav'
sf.write(output_path, y_shaped, sr)

print("ğŸ¥ BATERIA ORIGINAL:")
display(Audio(drums_path))

print("\nğŸ’¥ BATERIA COM PUNCH:")
display(Audio(output_path))
```

### Alargamento EstÃ©reo AvanÃ§ado

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STEREO ENHANCEMENT AVANÃ‡ADO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

y, sr = librosa.load(test_file, sr=44100, mono=False)

# Se for mono, converter para estÃ©reo
if len(y.shape) == 1:
    y = np.stack([y, y])

processor = AdvancedAudioProcessor()
y_wide = processor.stereo_enhance(
    y,
    width=1.7,      # 70% mais largo
    focus_freq=200  # Manter graves mono abaixo de 200Hz
)

# Salvar
output_path = '/content/stereo_wide.wav'
sf.write(output_path, y_wide.T, sr)  # Transpor para formato correto

print("ğŸ§ Use fones de ouvido para melhor percepÃ§Ã£o!\n")

print("ORIGINAL:")
display(Audio(test_file))

print("\nğŸµ STEREO ALARGADO:")
display(Audio(output_path))
```

### Auto-EQ Analyzer

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANÃLISE AUTOMÃTICA DE EQ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

y, sr = librosa.load(test_file, sr=44100)

processor = AdvancedAudioProcessor()
eq_suggestions = processor.auto_eq_analyzer(y, sr)

print("ğŸ“Š SUGESTÃ•ES DE EQ BASEADAS NA ANÃLISE:")
print("="*50)

for band, gain_db in eq_suggestions.items():
    sign = "+" if gain_db > 0 else ""
    bar = "â–ˆ" * int(abs(gain_db))
    print(f"{band:12s}: {sign}{gain_db:+5.1f} dB {bar}")

print("\nğŸ’¡ Use essas sugestÃµes em 'master_eq':")
print(f"master_eq = {eq_suggestions}")
```

---

## 4. Workflow Profissional Completo

### Workflow 1: Auto-ConfiguraÃ§Ã£o + Ajustes Manuais

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WORKFLOW HÃBRIDO: Auto + Manual
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# PASSO 1: AnÃ¡lise e auto-config
analyzer = SpectralAnalyzer()
analysis = analyzer.analyze_audio(test_file)
config_base = auto_configure(analysis, verbose=True)

# PASSO 2: Ajustes manuais baseados no tipo de mÃºsica
# Para mÃºsica eletrÃ´nica:
if 'electronic' in Path(test_file).name.lower():
    config_base['enhance_bass'] = True
    config_base['bass_enhancement_amount'] = 1.6
    config_base['master_eq']['bass'] = 2.0

    # Adicionar processamento avanÃ§ado
    config_base['advanced'] = {
        'harmonic_exciter': True,
        'stereo_enhance': True
    }

# Para vocal/acÃºstico:
elif 'vocal' in Path(test_file).name.lower():
    config_base['advanced'] = {
        'de_esser': True,
        'multiband_compress': True
    }

# PASSO 3: Processar
result = pipeline.process_audio(test_file, config=config_base)

# PASSO 4: Processamento adicional no resultado
y_final, sr = librosa.load(result['stages']['mastering']['output'])

processor = AdvancedAudioProcessor()

# Adicionar exciter sutil
y_final = processor.harmonic_exciter(y_final, sr, drive=0.2, mix=0.1)

# Alargamento estÃ©reo suave
if len(y_final.shape) > 1:
    y_final = processor.stereo_enhance(y_final, width=1.3)

# Salvar versÃ£o final
final_path = os.path.join(result['output_dir'], 'FINAL_ENHANCED.wav')
sf.write(final_path, y_final if len(y_final.shape) == 1 else y_final.T, sr)

print(f"âœ“ Processamento completo: {final_path}")
```

### Workflow 2: Processamento por Stems Customizado

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WORKFLOW: Processamento Customizado por Stem
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# PASSO 1: Separar stems
config_stems = {
    'separate_stems': True,
    'stem_separation_model': 'demucs',
    'process_stems_individually': False  # NÃ£o processar ainda
}

result = pipeline.process_audio(test_file, config=config_stems)
stems = result['stages']['stem_separation']

processor = AdvancedAudioProcessor()

# PASSO 2: Processar cada stem individualmente
processed_stems = {}

# VOCAL: De-esser + compressÃ£o + EQ
print("ğŸ¤ Processando VOCAL...")
y_vocal, sr = librosa.load(stems['vocals'])
y_vocal = processor.de_esser(y_vocal, sr, threshold_db=-12, ratio=5.0)
y_vocal = processor.multiband_compress(y_vocal, sr)
vocal_path = '/content/vocal_processed.wav'
sf.write(vocal_path, y_vocal, sr)
processed_stems['vocals'] = vocal_path

# DRUMS: Transient shaper + compressÃ£o
print("ğŸ¥ Processando BATERIA...")
y_drums, sr = librosa.load(stems['drums'])
y_drums = processor.transient_shaper(y_drums, sr, attack_gain=1.4, sustain_gain=0.8)
y_drums = processor.multiband_compress(
    y_drums, sr,
    ratios=[4.0, 5.0, 3.0, 2.0],  # Mais compressÃ£o nas baixas
    thresholds=[-20, -18, -22, -24]
)
drums_path = '/content/drums_processed.wav'
sf.write(drums_path, y_drums, sr)
processed_stems['drums'] = drums_path

# BASS: Exciter harmÃ´nico + limitaÃ§Ã£o
print("ğŸ¸ Processando BAIXO...")
y_bass, sr = librosa.load(stems['bass'])
y_bass = processor.harmonic_exciter(y_bass, sr, drive=0.4, mix=0.3)
y_bass = processor.adaptive_dynamics(y_bass, sr, target_crest_factor=3.0)
bass_path = '/content/bass_processed.wav'
sf.write(bass_path, y_bass, sr)
processed_stems['bass'] = bass_path

# OTHER: EQ automÃ¡tico + stereo enhance
print("ğŸ¹ Processando OUTROS...")
y_other, sr = librosa.load(stems['other'])
eq_suggestions = processor.auto_eq_analyzer(y_other, sr)
# Aplicar sugestÃµes de EQ (implementar aplicaÃ§Ã£o de EQ)
other_path = '/content/other_processed.wav'
sf.write(other_path, y_other, sr)
processed_stems['other'] = other_path

# PASSO 3: Reconstruir
from modules import StemSeparator

separator = StemSeparator()
final_mix_path = '/content/custom_mix.wav'

# Ganhos customizados por stem
stem_gains = {
    'vocals': 0.0,    # Sem alteraÃ§Ã£o
    'drums': -0.5,    # Reduzir levemente
    'bass': +1.0,     # RealÃ§ar
    'other': -1.5     # Reduzir
}

separator.reconstruct_from_stems(
    processed_stems,
    final_mix_path,
    stem_gains
)

# PASSO 4: MasterizaÃ§Ã£o final
from modules import AudioProcessor

final_processor = AudioProcessor()
y_mix, sr = librosa.load(final_mix_path)

# MasterizaÃ§Ã£o
y_mastered = final_processor.master(
    y_mix, sr,
    target_lufs=-14.0,
    master_eq={'bass': 0.5, 'mid': 0.0, 'presence': 1.5, 'treble': 1.2},
    add_presence=True
)

# Salvar versÃ£o final masterizada
mastered_path = '/content/FINAL_MASTERED_CUSTOM.wav'
sf.write(mastered_path, y_mastered, sr)

print("\n" + "="*60)
print("âœ“ WORKFLOW COMPLETO!")
print("="*60)
print(f"\nStems processados:")
for name, path in processed_stems.items():
    print(f"  â€¢ {name}: {path}")
print(f"\nMix reconstruÃ­do: {final_mix_path}")
print(f"Masterizado final: {mastered_path}")

# Ouvir resultado
print("\nğŸ§ RESULTADO FINAL:")
display(Audio(mastered_path))
```

### Workflow 3: ComparaÃ§Ã£o de MÃºltiplas VersÃµes

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WORKFLOW: ComparaÃ§Ã£o A/B/C/D
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

versions = {
    'Original': test_file,
    'Auto-Config': None,
    'Suave': None,
    'Demucs': None,
    'Custom': None
}

# Gerar versÃµes
print("Gerando versÃµes para comparaÃ§Ã£o...\n")

# Auto-config
analysis = analyzer.analyze_audio(test_file)
config_auto = auto_configure(analysis, verbose=False)
result = pipeline.process_audio(test_file, output_name='version_auto', config=config_auto)
versions['Auto-Config'] = result['stages']['mastering']['output']

# Suave
result = pipeline.process_audio(test_file, output_name='version_suave', config=CONFIG_SUAVE)
versions['Suave'] = result['stages']['mastering']['output']

# Demucs
result = pipeline.process_audio(test_file, output_name='version_demucs', config=CONFIG_DEMUCS)
versions['Demucs'] = result['stages']['mastering']['output']

# Custom (seu workflow preferido)
# ... (seu cÃ³digo customizado)
# versions['Custom'] = custom_output_path

# ComparaÃ§Ã£o
print("\n" + "="*60)
print("ğŸ§ COMPARAÃ‡ÃƒO DE VERSÃ•ES")
print("="*60)

for name, path in versions.items():
    print(f"\nğŸ“€ {name}:")
    if path:
        # AnÃ¡lise rÃ¡pida
        y, sr = librosa.load(path, sr=44100)
        rms = np.sqrt(np.mean(y**2))
        peak = np.max(np.abs(y))
        lufs_est = -23 + 20 * np.log10(rms + 1e-10)

        print(f"   LUFS: {lufs_est:.1f} | Peak: {peak:.3f} | RMS: {rms:.4f}")
        display(Audio(path))
    else:
        print("   (nÃ£o gerado)")

print("\nğŸ’¡ OuÃ§a todas as versÃµes e escolha a melhor!")
```

---

## ğŸ’¾ Salvar e Compartilhar ConfiguraÃ§Ãµes

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SALVAR CONFIGURAÃ‡Ã•ES FAVORITAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import json

# Sua configuraÃ§Ã£o favorita
MY_FAVORITE_CONFIG = {
    'reduce_noise': True,
    'noise_reduction_strength': 0.7,
    'restore_frequencies': True,
    'separate_stems': True,
    'stem_separation_model': 'demucs',
    'target_lufs': -14.0,
    'master_eq': {
        'bass': 1.0,
        'mid': 0.0,
        'presence': 2.0,
        'treble': 2.5
    },
    'advanced': {
        'de_esser': True,
        'harmonic_exciter': True
    }
}

# Salvar no Drive
config_path = '/content/drive/MyDrive/00-restore/my_favorite_config.json'
with open(config_path, 'w') as f:
    json.dump(MY_FAVORITE_CONFIG, f, indent=2)

print(f"âœ“ ConfiguraÃ§Ã£o salva: {config_path}")

# Carregar depois
with open(config_path, 'r') as f:
    loaded_config = json.load(f)

print("âœ“ ConfiguraÃ§Ã£o carregada e pronta para uso!")
```

---

**Estes exemplos cobrem todos os casos de uso profissionais do pipeline!** ğŸµğŸš€
